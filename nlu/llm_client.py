"""
LLM å®¢æˆ·ç«¯ - è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API
"""
from typing import Optional, Dict, Any
from nlu.models import LLMResponse
from utils.logger import setup_logger
import config
import requests


logger = setup_logger(__name__)

MAGIC_MIRROR_PROMPT = """
You are the Magic Mirror from Snow White.
You live inside a dark, shining mirror in the Queenâ€™s castle.
You speak in a slow, echoing, magical voice.
Your sentences are short and simple, like in a childrenâ€™s fairy tale.
You never leave your role. You never say you are an AI.

You always answer like the Magic Mirror:
- You speak with old, formal tone.
- You speak with calm truth.
- You never lie.
- You never flatter.
- You reveal what you see, as if looking through magic mist.
- You sometimes begin with phrases like â€œThe Mirror seesâ€¦â€ or â€œO Queen, hear the truth.â€

Stay fully inside the Snow White story world at all times.

IMPORTANT: Your answer must always be 30 English words or fewer.

"""





class LLMClient:
    """LLM API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None, api_url: Optional[str] = None):
        """
        åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        
        Args:
            api_key: API å¯†é’¥
            api_url: API ç«¯ç‚¹ URL
        """
        self.api_key = api_key or config.LLM_API_KEY
        self.api_url = api_url or config.LLM_API_URL
        self.headers = {
        "Authorization": f"Bearer {self.api_key}",
        "Content-Type": "application/json",
        }
        logger.info("ğŸ”§ åˆå§‹åŒ– LLM å®¢æˆ·ç«¯")
       
    
    def ask(self, prompt: str, system_prompt: Optional[str] = None) -> LLMResponse:
        """
        å‘ LLM å‘é€è¯·æ±‚
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜/æ–‡æœ¬
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            LLMResponse: LLM è¿”å›çš„å“åº”
        """
        logger.info(f"ğŸ¤” LLM å¤„ç†: {prompt[:50]}...")
        
        data = {
        "model": config.MODEL,
        "messages": [
        {"role": "system", "content": system_prompt or MAGIC_MIRROR_PROMPT},
        {"role": "user", "content": prompt}
        ]
    }
        response = requests.post(self.api_url, headers=self.headers, json=data)
        if response.status_code != 200:
            logger.error(f"âŒ LLM è¯·æ±‚å¤±è´¥: {response.status_code}")
            logger.error(f"âŒ LLM å“åº”: {response.text}")
            return LLMResponse(text="Error: Could not parse AI response.", raw_data={"error": response.text}, tokens_used=0, model=config.MODEL)
        
        try:
            response_json = response.json()
            ai_reply = response_json["choices"][0]["message"]["content"]
            tokens_used = response_json.get("usage", {}).get("total_tokens", 0)
            model = response_json.get("model", config.MODEL)
        except (KeyError, IndexError) as e:
            logger.error(f"âŒ è§£æ LLM å“åº”å¤±è´¥: {e}")
            ai_reply = "Error: Could not parse AI response."
            tokens_used = 0
            model = config.MODEL
            response_json = {"error": "Parse error"}
        
        return LLMResponse(text=ai_reply, raw_data=response_json, tokens_used=tokens_used, model=model)
        
        # # å ä½å®ç°ï¼šè¿”å›æ¨¡æ‹Ÿå“åº”
        # mock_response = self._mock_llm_response(prompt)
        # logger.info(f"ğŸ“ LLM å“åº”: {mock_response.text[:50]}...")
        # return mock_response
    
    def _mock_llm_response(self, prompt: str) -> LLMResponse:
        """
        æ¨¡æ‹Ÿ LLM å“åº”ï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            
        Returns:
            LLMResponse: æ¨¡æ‹Ÿå“åº”
        """
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œè¿”å›ç»“æ„åŒ– JSON
        prompt_lower = prompt.lower()
        
        if "å¤©æ°”" in prompt_lower:
            mock_text = '{"intent_type": "predefined_action", "action_name": "weather", "action_params": {}, "reply_text": "æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯"}'
        elif "æ–°é—»" in prompt_lower:
            mock_text = '{"intent_type": "predefined_action", "action_name": "news", "action_params": {}, "reply_text": "æ­£åœ¨ä¸ºæ‚¨è·å–æœ€æ–°æ–°é—»"}'
        elif "å®šæ—¶" in prompt_lower or "é—¹é’Ÿ" in prompt_lower:
            mock_text = '{"intent_type": "predefined_action", "action_name": "set_timer", "action_params": {"duration": 60}, "reply_text": "å·²è®¾ç½®å®šæ—¶å™¨"}'
        else:
            mock_text = '{"intent_type": "chat", "reply_text": "æˆ‘ç†è§£æ‚¨è¯´çš„ï¼š' + prompt + 'ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ï¼"}'
        
        return LLMResponse(
            text=mock_text,
            raw_data={"mock": True},
            tokens_used=100,
            model="mock-model"
        )

