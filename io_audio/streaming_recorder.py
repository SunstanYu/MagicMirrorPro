"""
æµå¼å½•éŸ³å’Œè¯†åˆ«æ¨¡å— - åˆå¹¶å”¤é†’ã€å½•éŸ³ã€æµå¼è¯†åˆ«
"""
import sounddevice as sd
import queue
import numpy as np
import json
import time
import threading
from typing import Optional
from vosk import Model, KaldiRecognizer
from google.cloud import speech
from asr.models import ASRResult
from utils.logger import setup_logger
import config

logger = setup_logger(__name__)


class StreamingRecorder:
    """æµå¼å½•éŸ³å’Œè¯†åˆ«å™¨ - é›†æˆå”¤é†’è¯æ£€æµ‹å’Œæµå¼è¯†åˆ«"""
    
    def __init__(self, wake_word: str = "hello", on_wake_word_detected=None):
        """åˆå§‹åŒ–æµå¼å½•éŸ³å™¨
        
        Args:
            wake_word: å”¤é†’è¯
            on_wake_word_detected: å”¤é†’è¯æ£€æµ‹å›è°ƒå‡½æ•°ï¼Œæ£€æµ‹åˆ°å”¤é†’è¯æ—¶è°ƒç”¨
        """
        self.wake_word = wake_word.lower()
        self.sample_rate = config.AUDIO_SAMPLE_RATE
        self.block_size = 8000
        self.volume_gain = 10.0
        self.device_id = 1
        self.on_wake_word_detected = on_wake_word_detected
        
        # åˆå§‹åŒ– Vosk æ¨¡å‹
        try:
            model_path = config.VOSK_MODEL_PATH
            if not model_path.exists():
                raise ValueError(f"Vosk æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            self.vosk_model = Model(str(model_path))
            self.vosk_rec = KaldiRecognizer(self.vosk_model, self.sample_rate)
            self.vosk_rec.SetWords(True)  # å¯ç”¨å•è¯çº§åˆ«çš„è¯†åˆ«
            logger.info(f"âœ… Vosk æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        except Exception as e:
            logger.error(f"âŒ Vosk æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
        
        # åˆå§‹åŒ– Google ASR å®¢æˆ·ç«¯
        try:
            self.google_client = speech.SpeechClient.from_service_account_file(
                str(config.GOOGLE_ASR_CREDENTIALS_PATH)
            )
            logger.info("âœ… Google ASR å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Google ASR å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # çŠ¶æ€å˜é‡
        self.audio_queue = queue.Queue()
        self.is_recording = False
        self._wake_word_detection_active = False  # å”¤é†’è¯æ£€æµ‹æ¿€æ´»æ ‡å¿—
        
        # Google æµå¼è¯†åˆ«ç›¸å…³å˜é‡ï¼ˆç”¨äºç±»æ–¹æ³•è®¿é—®ï¼‰
        self._google_queue = None
        self._streaming_active = False
        self._final_result = None
        self._last_recognition_time = None
        self._recognition_started = False
        self._streaming_config = None
        
        # éŸ³é¢‘æµå’Œè®¾å¤‡ä¿¡æ¯ï¼ˆåœ¨åˆå§‹åŒ–æ—¶è®¾ç½®ï¼‰
        self._audio_stream = None
        self._device_info = None
        self._actual_sample_rate = self.sample_rate
        self._channels = 1
        self._needs_resample = False
        
        # åˆå§‹åŒ–å¹¶å¯åŠ¨éŸ³é¢‘æµ
        self._init_audio_stream()
        
        logger.info("âœ… æµå¼å½•éŸ³å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_audio_stream(self):
        """åˆå§‹åŒ–å¹¶å¯åŠ¨éŸ³é¢‘æµï¼ˆåœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨ï¼Œä¿æŒä¸€ç›´è¿è¡Œï¼‰"""
        try:
            # åˆ—å‡ºæ‰€æœ‰å¯ç”¨è®¾å¤‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            all_devices = sd.query_devices()
            logger.info("ğŸ“‹ å¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
            for i, dev in enumerate(all_devices):
                if dev.get('max_input_channels', 0) > 0:
                    logger.info(f"  è®¾å¤‡ {i}: {dev['name']} (è¾“å…¥é€šé“: {dev.get('max_input_channels', 0)})")
            
            # å°è¯•ä½¿ç”¨æŒ‡å®šè®¾å¤‡
            try:
                self._device_info = sd.query_devices(self.device_id)
                self._actual_sample_rate = int(self._device_info['default_samplerate'])
                max_input_channels = self._device_info.get('max_input_channels', 0)
                
                if max_input_channels < 1:
                    logger.warning(f"âš ï¸ è®¾å¤‡ {self.device_id} ä¸æ”¯æŒè¾“å…¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è®¾å¤‡")
                    self._device_info = None
                else:
                    self._channels = 1  # ä½¿ç”¨å•å£°é“
                    logger.info(f"âœ… ä½¿ç”¨è®¾å¤‡ {self.device_id}: {self._device_info['name']} (é‡‡æ ·ç‡: {self._actual_sample_rate}Hz, é€šé“: {self._channels})")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–è®¾å¤‡ {self.device_id} ä¿¡æ¯å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡")
                self._device_info = None
                # ä½¿ç”¨é»˜è®¤è®¾å¤‡æ—¶ï¼Œå°è¯•è·å–é»˜è®¤é‡‡æ ·ç‡
                try:
                    default_device = sd.query_devices(kind='input')
                    self._actual_sample_rate = int(default_device['default_samplerate'])
                except:
                    self._actual_sample_rate = self.sample_rate
            
            self._needs_resample = (self._actual_sample_rate != self.sample_rate)
            
            # å¯åŠ¨éŸ³é¢‘æµï¼ˆä¿æŒä¸€ç›´è¿è¡Œï¼‰
            self._audio_stream = sd.InputStream(
                device=self.device_id if self._device_info else None,
                samplerate=self._actual_sample_rate,
                blocksize=self.block_size,
                dtype="int16",
                channels=self._channels,
                callback=self.audio_callback
            )
            self._audio_stream.start()
            logger.info("âœ… éŸ³é¢‘æµå·²å¯åŠ¨å¹¶ä¿æŒè¿è¡Œ")
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–éŸ³é¢‘æµå¤±è´¥: {e}")
            raise
    
    def audio_callback(self, indata, frames, time, status):
        """éŸ³é¢‘é‡‡é›†å›è°ƒ"""
        if status:
            logger.warning(f"âš ï¸ éŸ³é¢‘çŠ¶æ€: {status}")
        
        # å¤„ç†å¤šå£°é“éŸ³é¢‘ï¼Œå–ç¬¬ä¸€ä¸ªå£°é“
        if indata.ndim > 1:
            audio_chunk = indata[:, 0].copy()
        else:
            audio_chunk = indata.copy()
        
        if audio_chunk.dtype != np.int16:
            if audio_chunk.dtype in [np.float32, np.float64]:
                audio_chunk = (audio_chunk * 32767).astype(np.int16)
            else:
                audio_chunk = audio_chunk.astype(np.int16)
        
        # å®æ—¶æ”¾å¤§éŸ³é‡
        audio_float = audio_chunk.astype(np.float32) * self.volume_gain
        audio_chunk = np.clip(audio_float, -32768, 32767).astype(np.int16)
        
        self.audio_queue.put(audio_chunk.tobytes())
    
    def _detect_wake_word(self, audio_data: bytes) -> bool:
        """æ£€æµ‹å”¤é†’è¯"""
        try:
            # æ£€æŸ¥å®Œæ•´ç»“æœ
            if self.vosk_rec.AcceptWaveform(audio_data):
                result = json.loads(self.vosk_rec.Result())
                text = result.get('text', '').strip().lower()
                if text:
                    logger.info(f"ğŸ” Vosk å®Œæ•´ç»“æœ: {text}")
                if self.wake_word in text:
                    logger.info(f"âœ… åœ¨å®Œæ•´ç»“æœä¸­æ£€æµ‹åˆ°å”¤é†’è¯ '{self.wake_word}'")
                    return True
            
            # æ£€æŸ¥éƒ¨åˆ†ç»“æœ
            partial = json.loads(self.vosk_rec.PartialResult())
            partial_text = partial.get('partial', '').strip().lower()
            if partial_text:
                logger.info(f"ğŸ” Vosk éƒ¨åˆ†ç»“æœ: {partial_text}")
            if self.wake_word in partial_text:
                logger.info(f"âœ… åœ¨éƒ¨åˆ†ç»“æœä¸­æ£€æµ‹åˆ°å”¤é†’è¯ '{self.wake_word}'")
                return True
        except Exception as e:
            logger.warning(f"âš ï¸ å”¤é†’è¯æ£€æµ‹å¼‚å¸¸: {e}")
        return False
    
    def _resample_audio(self, data: bytes, actual_rate: int) -> bytes:
        """é™é‡‡æ ·éŸ³é¢‘"""
        audio_chunk = np.frombuffer(data, dtype=np.int16)
        step_ratio = actual_rate / self.sample_rate
        
        if abs(step_ratio - round(step_ratio)) < 0.001:
            step = int(round(step_ratio))
            audio_chunk = audio_chunk[::step]
        else:
            try:
                from scipy import signal
                new_length = int(len(audio_chunk) * (self.sample_rate / actual_rate))
                audio_chunk = signal.resample(audio_chunk, new_length).astype(np.int16)
            except ImportError:
                return data
        return audio_chunk.tobytes()
    
    def _save_asr_result(self, result: ASRResult):
        """ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ–‡ä»¶"""
        try:
            if not result.text:
                return
            
            with open(config.ASR_RESULT_FILE, "w", encoding="utf-8") as f:
                f.write(result.text + "\n")
            
            logger.info(f"ğŸ’¾ è¯†åˆ«ç»“æœå·²ä¿å­˜: {result.text}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¯†åˆ«ç»“æœå¤±è´¥: {e}")
    
    def _generate_google_requests(self):
        """ç”ŸæˆéŸ³é¢‘è¯·æ±‚çš„ç”Ÿæˆå™¨"""
        try:
            while self._streaming_active:
                try:
                    audio_data = self._google_queue.get(timeout=0.1)
                    yield speech.StreamingRecognizeRequest(audio_content=audio_data)
                except queue.Empty:
                    continue
        except GeneratorExit:
            pass
    
    def _send_audio_to_google(self, data):
        """å‘é€éŸ³é¢‘æ•°æ®åˆ° Google APIï¼ˆæ·»åŠ åˆ°é˜Ÿåˆ—ï¼‰"""
        if self._google_queue is not None:
            self._google_queue.put(data)
    
    def _process_google_responses(self):
        """å¤„ç†è¯†åˆ«å“åº”ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        try:
            responses = self.google_client.streaming_recognize(
                config=self._streaming_config,
                requests=self._generate_google_requests()
            )
            
            for response in responses:
                if not response.results:
                    continue
                
                result = response.results[0]
                if not result.alternatives:
                    continue
                
                transcript = result.alternatives[0].transcript.strip()
                
                if result.is_final:
                    if transcript:
                        logger.info(f"ğŸ“ è¯†åˆ«åˆ°å¥å­: {transcript}")
                        self._recognition_started = True
                        self._final_result = ASRResult(
                            text=transcript,
                            confidence=result.alternatives[0].confidence if hasattr(result.alternatives[0], 'confidence') else 0.0,
                            language_code="en-US"
                        )
                        # ç›´æ¥ä¿å­˜è¯†åˆ«ç»“æœ
                        self._save_asr_result(self._final_result)
                        self._last_recognition_time = time.time()
                        # è¯†åˆ«åˆ°æœ€ç»ˆç»“æœåï¼Œç«‹å³åœæ­¢è¯†åˆ«æµç¨‹ï¼Œè®© record_and_transcribe() æ›´å¿«è¿”å›
                        self._streaming_active = False
                        logger.info("âœ… è¯†åˆ«åˆ°æœ€ç»ˆç»“æœï¼Œåœæ­¢è¯†åˆ«æµç¨‹")
                else:
                    if transcript:
                        self._recognition_started = True
                        self._last_recognition_time = time.time()
        except Exception as e:
            logger.error(f"âŒ Google æµå¼è¯†åˆ«é”™è¯¯: {e}")
    
    def record_and_transcribe(self) -> Optional[ASRResult]:
        """
        å®Œæ•´çš„å½•éŸ³å’Œè¯†åˆ«æµç¨‹ï¼šç­‰å¾…å”¤é†’è¯ -> æµå¼è¯†åˆ«
        éŸ³é¢‘æµå·²ç»åœ¨åˆå§‹åŒ–æ—¶å¯åŠ¨ï¼Œè¿™é‡Œåªè¿›è¡Œå”¤é†’è¯æ£€æµ‹å’Œè¯†åˆ«é€»è¾‘
        åªå¤„ç†ä¸€æ¬¡å”¤é†’å’Œè¯†åˆ«ï¼Œç„¶åè¿”å›ç»“æœï¼ˆç”±è°ƒç”¨è€…å†³å®šæ˜¯å¦ç»§ç»­å¾ªç¯ï¼‰
        
        Returns:
            ASRResult: æœ€ç»ˆè¯†åˆ«ç»“æœï¼Œå¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°åˆ™è¿”å› None
        """
        if not self._audio_stream or not self._audio_stream.active:
            logger.error("âŒ éŸ³é¢‘æµæœªè¿è¡Œï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«")
            return None
        
        logger.info(f"ğŸ¯ ç­‰å¾…å”¤é†’è¯ '{self.wake_word}'...")
        self.is_recording = True
        self._wake_word_detection_active = True
        
        try:
            # é‡ç½® Vosk è¯†åˆ«å™¨çŠ¶æ€ï¼ˆå¼€å§‹æ–°çš„è¯†åˆ«ä¼šè¯ï¼‰
            self.vosk_rec = KaldiRecognizer(self.vosk_model, self.sample_rate)
            self.vosk_rec.SetWords(True)
            
            wake_word_detected = False
            
            # ç¬¬ä¸€æ­¥ï¼šç­‰å¾…å”¤é†’è¯ï¼ˆæŒç»­å¾ªç¯ç›´åˆ°æ£€æµ‹åˆ°ï¼‰
            logger.info(f"ğŸ¤ æ­£åœ¨ç›‘å¬ï¼Œè¯·è¯´ '{self.wake_word}'...")
            
            while self.is_recording and not wake_word_detected:
                try:
                    data = self.audio_queue.get(timeout=0.5)
                    if self._needs_resample:
                        data = self._resample_audio(data, self._actual_sample_rate)
                    
                    # æ£€æµ‹å”¤é†’è¯
                    if self._detect_wake_word(data):
                        wake_word_detected = True
                        logger.info(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯ '{self.wake_word}'")
                        # è°ƒç”¨å”¤é†’è¯æ£€æµ‹å›è°ƒ
                        if self.on_wake_word_detected:
                            try:
                                self.on_wake_word_detected()
                            except Exception as e:
                                logger.warning(f"âš ï¸ å”¤é†’è¯å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                        break
                except queue.Empty:
                    continue
            
            if not wake_word_detected:
                # å¦‚æœåœæ­¢å½•éŸ³ä½†æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œè¿”å› None
                return None
            
            # æ£€æµ‹åˆ°å”¤é†’è¯åï¼Œç»™ç”¨æˆ·ä¸€ç‚¹æ—¶é—´å‡†å¤‡è¯´è¯
            logger.info("âœ… æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå‡†å¤‡å¼€å§‹è¯†åˆ«...")
            
            # ç¬¬äºŒæ­¥ï¼šGoogle æµå¼è¯†åˆ«
            logger.info("ğŸ”Š å¼€å§‹ Google æµå¼è¯†åˆ«ï¼Œè¯·è¯´è¯...")
            self._google_queue = queue.Queue()
            self._final_result = None
            self._last_recognition_time = None
            self._streaming_active = True
            self._recognition_started = False
            
            # Google æµå¼è¯†åˆ«é…ç½®
            recognition_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=self.sample_rate,
                language_code="en-US",
                enable_automatic_punctuation=True,
            )
            self._streaming_config = speech.StreamingRecognitionConfig(
                config=recognition_config,
                interim_results=True,
            )
            
            # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
            recognition_thread = threading.Thread(target=self._process_google_responses, daemon=True)
            recognition_thread.start()
            
            # æŒç»­å½•éŸ³å¹¶å‘é€åˆ° Google
            INITIAL_WAIT_DURATION = 5.0  # åˆå§‹ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œç»™ç”¨æˆ·æ—¶é—´å¼€å§‹è¯´è¯
            NO_RECOGNITION_DURATION = 3.0  # æ— è¯†åˆ«å†…å®¹æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            start_time = time.time()
            
            while self.is_recording and self._streaming_active:
                try:
                    data = self.audio_queue.get(timeout=0.5)
                    if self._needs_resample:
                        data = self._resample_audio(data, self._actual_sample_rate)
                    
                    # å‘é€éŸ³é¢‘æ•°æ®åˆ° Google API
                    self._send_audio_to_google(data)
                    
                    # å¦‚æœè¿˜æ²¡å¼€å§‹è¯†åˆ«åˆ°å†…å®¹ï¼Œæ£€æŸ¥åˆå§‹ç­‰å¾…æ—¶é—´
                    if not self._recognition_started:
                        elapsed = time.time() - start_time
                        if elapsed >= INITIAL_WAIT_DURATION:
                            logger.info("â¹ï¸ åˆå§‹ç­‰å¾…æ—¶é—´ç»“æŸï¼Œæœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œåœæ­¢è¯†åˆ«")
                            self._streaming_active = False
                            break
                    else:
                        # å¦‚æœå·²ç»å¼€å§‹è¯†åˆ«ï¼Œæ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æ— æ–°å†…å®¹
                        if self._last_recognition_time is not None:
                            if time.time() - self._last_recognition_time >= NO_RECOGNITION_DURATION:
                                logger.info("â¹ï¸ é•¿æ—¶é—´æ— è¯†åˆ«å†…å®¹ï¼Œåœæ­¢è¯†åˆ«")
                                self._streaming_active = False
                                break
                except queue.Empty:
                    continue
            
            # ç­‰å¾…è¯†åˆ«çº¿ç¨‹å®Œæˆ
            recognition_thread.join(timeout=2.0)
            
            # è¿”å›è¯†åˆ«ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            return self._final_result if (self._final_result and self._final_result.text) else None
                
        except Exception as e:
            logger.error(f"âŒ å½•éŸ³è¯†åˆ«é”™è¯¯: {e}")
            return None
        finally:
            self.is_recording = False
            self._wake_word_detection_active = False
    
    def stop(self):
        """åœæ­¢å½•éŸ³å’Œå…³é—­éŸ³é¢‘æµ"""
        self.is_recording = False
        self._wake_word_detection_active = False
        
        if self._audio_stream and self._audio_stream.active:
            try:
                self._audio_stream.stop()
                self._audio_stream.close()
                logger.info("â¹ï¸ éŸ³é¢‘æµå·²å…³é—­")
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é—­éŸ³é¢‘æµæ—¶å‡ºé”™: {e}")
        
        logger.info("â¹ï¸ åœæ­¢å½•éŸ³")
